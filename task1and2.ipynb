{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ’» Laptop Price Prediction\n",
    "\n",
    "This notebook demonstrates a complete pipeline for predicting laptop prices using **data preprocessing, exploratory data analysis (EDA), and machine learning models**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"laptopData.csv\")\n",
    "print(\"Initial shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Handle Missing Values\n",
    "- Drop rows with more than 50% missing values.\n",
    "- Fill numeric columns with **median** (robust to outliers).\n",
    "- Fill categorical columns with **mode** (most frequent value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with too many NaNs\n",
    "df = df.dropna(thresh=df.shape[1]//2)\n",
    "\n",
    "# Fill numeric NaNs with median\n",
    "df = df.fillna(df.median(numeric_only=True))\n",
    "\n",
    "# Fill categorical NaNs with mode\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = df[col].fillna(df[col].mode()[0])\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Encode Categorical Variables\n",
    "Convert string columns into numerical codes using **Label Encoding**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Trainâ€“Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop(\"Price\", axis=1)\n",
    "y = df[\"Price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis (EDA)\n",
    "- Distribution plots (Price, Weight)\n",
    "- Scatterplot (Weight vs Price)\n",
    "- Boxplots to identify outliers\n",
    "- Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Summary stats\n",
    "df[[\"Price\", \"Weight\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df['Price'], kde=True)\n",
    "plt.title('Distribution of Price')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(df['Weight'], kde=True)\n",
    "plt.title('Distribution of Weight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='Weight', y='Price', data=df)\n",
    "plt.title('Weight vs. Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(y=df['Price'])\n",
    "plt.title('Box Plot of Price')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=df['Weight'])\n",
    "plt.title('Box Plot of Weight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Training\n",
    "- Scale features using **StandardScaler**\n",
    "- Train a baseline model (**Linear Regression**)\n",
    "- Compare with **Random Forest Regressor** (tuned with different n_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Linear Regression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_scaled, y_train)\n",
    "y_pred = lin_reg.predict(X_test_scaled)\n",
    "\n",
    "print(\"Linear Regression MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"Linear Regression R2:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor tuning\n",
    "for n in [50, 100, 200]:\n",
    "    rf = RandomForestRegressor(n_estimators=n, random_state=42)\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "    preds = rf.predict(X_test_scaled)\n",
    "    print(f\"RandomForest (n_estimators={n}) -> MAE: {mean_absolute_error(y_test, preds):.2f}, R2: {r2_score(y_test, preds):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Results & Insights\n",
    "- **Linear Regression**:\n",
    "  - MAE: ~20,287\n",
    "  - RÂ²: 0.47\n",
    "  - Explains ~47% variance but with large error â†’ not reliable.\n",
    "\n",
    "- **Random Forest**:\n",
    "  - MAE: ~10,000\n",
    "  - RÂ²: ~0.80\n",
    "  - Explains ~80% variance, much better performance.\n",
    "  - Increasing trees beyond 100 gives diminishing returns.\n",
    "\n",
    "âœ… Conclusion: **Random Forest** is a far better choice for predicting laptop prices in this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
